Credit Card Fraud Detection System
This project implements a scalable fraud detection system using Big Data technologies such as Apache Spark, HDFS, and Random Forest machine learning models. The system processes large datasets, applies machine learning techniques to detect fraudulent transactions, and visualizes the results effectively.

Features
Efficient data preprocessing using Apache Spark.
Machine learning-based fraud detection using Random Forest.

System Requirements:
To successfully run the application, ensure the following components are installed and configured on your system:

Java Development Kit (JDK): Version 8 or later.
Ensure JAVA_HOME is set correctly.
Hadoop: Version 3.4.1 or compatible.
Ensure HADOOP_HOME is configured.
Apache Spark: Version 3.x or compatible.
Ensure SPARK_HOME is configured.
Python: Version 3.8 or later.
pip Packages:
pandas

### Commands to Run the Files and Expected Outputs


 1. **`preprosess.py`**
   - **Command to Run:**

     python3 preprosess.py <input_csv_path> <output_parquet_path>
     ```
     - Replace `<input_csv_path>` with the path to your input CSV file (e.g., `creditcard.csv`).
     - Replace `<output_parquet_path>` with the desired output path for the processed Parquet file (e.g., `processed_data.parquet`).

     python3 preprosess.py /path/to/creditcard.csv /path/to/processed_data.parquet
     ```

   - **Expected Output:**
     - Logs indicating the start of preprocessing.
     - The system will:
       1. Read the CSV file.
       2. Remove duplicates and process data.
       3. Save the preprocessed data as a Parquet file.
     - Final output will include a success message:
      
       Preprocessing Pipeline: Completed successfully.
   


2. **`train.py`**
   - **Command to Run:**
 
     python3 train.py <input_parquet_path>
 
     - Replace `<input_parquet_path>` with the path to the preprocessed Parquet file generated by `preprosess.py`.

   
     python3 train.py /path/to/processed_data.parquet


   - **Expected Output:**
     - Logs showing:
       1. Reading the Parquet file.
       2. Splitting data into training and test sets.
       3. Training the Random Forest model.
       4. Model evaluation and accuracy calculation.
     - Final output:
       ```
       Successfully read the parquet file with [number_of_records] records.
       Training Pipeline: Model training completed. Overall accuracy is [accuracy_value].
       Model Accuracy: [accuracy_value]
       ```
     - The trained model will be saved in the `model/` directory.


3. **`inference.py`**
   - **Commands to Run:**
     - **Training Command:**

       python3 inference.py train <input_csv_path> <model_save_path>
   
       - Replace `<input_csv_path>` with the CSV file path for training (e.g., `creditcard.csv`).
       - Replace `<model_save_path>` with the path where the model will be saved.

       
       python3 inference.py train /path/to/creditcard.csv /path/to/model_directory
   

       **Expected Output:**
       - Logs showing:
         1. Loading the training data.
         2. Training the Random Forest model.
       - Final message:
    
         Training completed. Model saved at /path/to/model_directory.
        

     - **Inference Command:**
    
       python3 inference.py infer <input_csv_path> <model_load_path>
   
       - Replace `<input_csv_path>` with the CSV file for inference.
       - Replace `<model_load_path>` with the path to the trained model directory.

   
       python3 inference.py infer /path/to/creditcard.csv /path/to/model_directory
    

       **Expected Output:**
        The script will process transaction records and output a predictions.json file. Each transaction will include the following fields:

        prediction_id: A unique identifier for the prediction (UUID format).
        amount: The transaction amount (from the input dataset).
        actual_class: The actual class label from the dataset (0 for legitimate, 1 for fraudulent).
        predicted_class: The fraud prediction made by the model (0 or 1).
   


### Summary of Expected Outputs
1. **`preprosess.py`:** Generates a cleaned and preprocessed Parquet file.
2. **`train.py`:** Trains a Random Forest model, evaluates accuracy, and saves the model.
3. **`inference.py`: Uses the trained model to infer on new transaction data and prints predictions directly to the console. The predictions include details such as a unique prediction ID, transaction amount, actual class, and the predicted class for each record.
